# Experiment Workbench

This repository is the central R&D workbench for SnoIQ. It is used for prototyping, experimentation, and validating pipelines before they are "graduated" to production-ready microservices.

## Folder Structure & Reasoning

### `/data`

* **Purpose:** To hold small, sample data files for quick, local tests.
* **Contains:** Sample `.grib2` files, `.tif` files, or small CSVs.
* **NOTE:** This folder is **NOT** for the multi-terabyte dataset. The full dataset is versioned with **DVC** and stored in our object storage (MinIO). This folder is only for files small enough to commit to Git (or be used in a quick test).

### `/notebooks`

* **Purpose:** The R&D "sandbox." This is where all interactive experimentation, data exploration, and model prototyping happens.
* **Contains:** `.ipynb` (Jupyter) files.
* **Workflow:** This folder is expected to be "messy." It's a lab notebook for trying new ideas. When a concept is proven, the clean logic is "graduated" into the `/src` folder.

### `/src`

* **Purpose:** To store clean, reusable, production-quality code.
* **Contains:** `.py` Python files, organized as a proper package.
* **Workflow:** Code here should be well-documented and unit-tested. Notebooks in `/notebooks` should import functions *from* this folder. This is the "contract" we hand off to our coding agents for final delivery.

### `/tests`

* **Purpose:** To hold the "golden tests" and unit tests for the code in `/src`.
* **Contains:** `test_*.py` files (using `pytest`).
* **Workflow:** These tests are the "contract" for our agents. When an agent refactors code in `/src`, its primary goal is to ensure all tests in this folder pass.

---

### Project Folder Structure (The "Blueprint")

```markdown
snoiq-experiments/
â”‚
â”œâ”€â”€ .pixi/                # (Ignored by Git) The local environment managed by pixi
â”œâ”€â”€ .dvc/                 # (Checked into Git) DVC's internal metadata
â”œâ”€â”€ .dvcignore            # (Checked into Git) Tells DVC to ignore temp files
â”œâ”€â”€ .gitignore            # (Checked into Git) Ignores .pixi/, .venv/, __pycache__/
â”‚
â”œâ”€â”€ pixi.toml             # ðŸ”µ The MASTER file for your environment (replaces requirements.txt)
â”œâ”€â”€ pixi.lock             # ðŸ”µ The lockfile that makes your environment reproducible
â”‚
â”œâ”€â”€ data/
â”‚   â”‚   # This folder contains sample data for testing
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ sample_hrrr_run.grib2
â”‚   â”‚
â”‚   â”œâ”€â”€ grids/
â”‚   â”‚   â”‚   # This .npz file is your "source artifact"
â”‚   â”‚   â”œâ”€â”€ grid_latlon__model-HRRRv4.npz.dvc   <-- 1KB DVC pointer file
â”‚   â”‚   â””â”€â”€ .gitignore                          <-- Ignores the actual .npz file
â”‚   â”‚
â”‚   â””â”€â”€ (Your 6TB Parquet Data Lake is NOT here. It's in MinIO, managed by DVC)
â”‚
â”œâ”€â”€ notebooks/            # ðŸ”¬ Your R&D "lab" for messy, interactive experiments
â”‚   â”œâ”€â”€ 01-ingestion/
â”‚   â”‚   â”œâ”€â”€ test_grib_parsing.ipynb
â”‚   â”‚   â””â”€â”€ test_homr_api.ipynb
â”‚   â”‚
â”‚   â”œâ”€â”€ 02-feature-engineering/
â”‚   â”‚   â””â”€â”€ test_grid_join.ipynb
â”‚   â”‚
â”‚   â””â”€â”€ 03-training/
â”‚       â””â”€â”€ initial_model_training.ipynb
â”‚
â”œâ”€â”€ src/                  # ðŸ“¦ Your clean, reusable Python package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ hrrr.py       # <-- Your graduated, clean HRRR Prefect flow
â”‚   â”‚   â””â”€â”€ uscrn.py      # <-- Your graduated, clean USCRN flow
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ grid.py       # <-- Your `get_5x5_grid` function
â”‚   â”‚   â””â”€â”€ build_features.py
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train.py      # <-- Your graduated `mlflow` training script
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ schema.py     # <-- Your Postgres table definitions (GridReference)
â”‚
â””â”€â”€ tests/                #  CONTRACT: The "golden tests" for your agent
    â”œâ”€â”€ test_ingestion.py
    â””â”€â”€ test_features.py
```

### The Core Workflow (How You Use It)

1. Setup: You run `pixi install` once. This builds your complete environment (Python, CUDA, Pygrib, etc.).

2. R&D: You run `pixi run jupyter lab` (or just open a `.ipynb` file in VS Code). You experiment in the `notebooks/` folder.

3. Graduate: You copy/paste your working functions from the notebook into the `src/` folder.

4. Test: You write a "golden test" in the `tests/` folder to prove your `src/` code works.

5. Run Pipeline: You run your full, clean pipelines using `prefect` and `pixi`:

   * `pixi run python src/ingestion/hrrr.py` (to run the Prefect flow)

   * `pixi run python src/training/train.py` (to run the MLflow training)

6. Handoff: You give your coding agent the `src/` code and `tests/` as its "contract" to build the production repos.